# Shannon Portrait - InfoCodec

**Information Coding & Encoding**: A research and educational tool for exploring Claude Shannon's Information Theory through practical image compression experiments.

## üéØ Project Overview

This project demonstrates Shannon's fundamental concepts through the thought experiment of transmitting 2D images over a 1D wire:

- **2D ‚Üí 1D**: Various encoding/compression methods
- **Transmission**: Simulated 1D channel
- **1D ‚Üí 2D**: Reconstruction with quality analysis
- **Analysis**: Information theory metrics and AI-generated reports

## üöÄ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/shannon-portrait.git
cd shannon-portrait

# Install the package
pip install -e .

# Or install from PyPI (when published)
pip install shannon-portrait
```

### CLI Usage

```bash
conda create -n st python=3.11
conda activate st


# Encode an image
cd data/input/image
infocodec encode --input shannon-4.png  --method huffman

# Decode compressed data
infocodec decode --input ~/projects/digital-duck/shannon-portrait/data/output/image/shannon-4_image_huffman.dat --output ~/projects/digital-duck/shannon-portrait/data/input/image/shannon-4-restored.png

# Benchmark all methods
infocodec benchmark --input shannon.png --methods all

# Launch interactive UI
infocodec-ui
```

### Streamlit UI

```bash
# Launch web interface
streamlit run infocodec/ui/InfoCoDec.py

# Or via CLI
infocodec-ui
```

## üìö Features

### Compression Methods

| Method | Type | Best For | Compression | Quality |
|--------|------|----------|-------------|---------|
| Naive | Baseline | Comparison | 1.0x | Perfect |
| RLE | Lossless | Block patterns | 4-10x | Perfect |
| Differential | Lossless | Smooth gradients | 2-5x | Perfect |
| Huffman | Lossless | General purpose | 1.5-3x | Perfect |
| Sparse | Lossy | Quick preview | 10-50x | Variable |
| DCT | Lossy | Photos (JPEG-style) | 5-20x | Variable |

### Information Theory Metrics

- **Shannon Entropy**: H(X) = -Œ£ p(x) log‚ÇÇ(p(x))
- **PSNR**: Peak Signal-to-Noise Ratio
- **SSIM**: Structural Similarity Index
- **Compression Ratio**: Original size / Compressed size
- **Bits per Pixel**: Total bits / Number of pixels

### Multi-Page UI

1. **‚öôÔ∏è Settings**: Configure algorithms, LLM integration, caching
2. **üì§ Encode**: Upload and compress images
3. **üì• Decode**: Reconstruct from compressed data
4. **üìä Diff**: Visual and quantitative quality analysis
5. **üìù Summarize**: AI-generated experimental reports

## üèóÔ∏è Project Structure

```
shannon-portrait/
‚îú‚îÄ‚îÄ infocodec/                  # Main package
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ cli.py                  # Click CLI
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py             # Abstract base classes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py          # Information theory metrics
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ compressors/        # Compression algorithms
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ image/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ naive.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ rle.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ differential.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ huffman.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ sparse.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ dct.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reconstructors/     # Reconstruction algorithms
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ image/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ direct.py
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ progressive.py
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ error_recovery.py
‚îÇ   ‚îú‚îÄ‚îÄ ui/                     # Streamlit interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ InfoCoDec.py        # Main app
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/              # Multi-page app
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1_‚öôÔ∏è_Settings.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2_üì§_Encode.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 3_üì•_Decode.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 4_üìä_Diff.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 5_üìù_Summarize.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ components/         # Reusable UI components
‚îÇ   ‚îî‚îÄ‚îÄ utils/                  # Utilities
‚îÇ       ‚îú‚îÄ‚îÄ image_utils.py
‚îÇ       ‚îú‚îÄ‚îÄ config.py
‚îÇ       ‚îî‚îÄ‚îÄ openrouter.py       # LLM integration
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îÇ       ‚îî‚îÄ‚îÄ shannon_portrait.png
‚îú‚îÄ‚îÄ tests/                      # Unit tests
‚îú‚îÄ‚îÄ docs/                       # Documentation
‚îú‚îÄ‚îÄ notebooks/                  # Jupyter tutorials
‚îú‚îÄ‚îÄ setup.py                    # Package setup
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md

```

## üî¨ Research Use Cases

### 1. Information Representation Study

Explore how different encodings represent the same information:

```python
from infocodec.core.compressors import COMPRESSORS
from infocodec.utils.image_utils import load_image

image = load_image("shannon.png")

for method_name, compressor_class in COMPRESSORS.items():
    compressor = compressor_class()
    compressed, metadata = compressor.compress(image)
    stats = compressor.get_stats()
    print(f"{method_name}: {stats['entropy']:.2f} bits/pixel")
```

### 2. Compression Algorithm Comparison

Benchmark multiple methods:

```bash
infocodec benchmark --input test_images/ --methods all --output results/
```

### 3. Rate-Distortion Analysis

Study the trade-off between compression and quality:

```python
qualities = [1.0, 0.9, 0.8, 0.7, 0.5, 0.3, 0.1]
for q in qualities:
    # Compress at different quality levels
    # Measure PSNR vs. compression ratio
```

### 4. Educational Demonstrations

Use the Streamlit UI for interactive teaching:

1. Show students entropy of different patterns
2. Demonstrate compression effectiveness
3. Visualize reconstruction quality
4. Compare theoretical vs. practical results

## ü§ñ LLM Integration (OpenRouter)

### Setup

1. Get API key from [OpenRouter.ai](https://openrouter.ai/keys)
2. Configure in Settings page or environment variable:

```bash
export OPENROUTER_API_KEY="your-key-here"
```

### Supported Models

- `anthropic/claude-3.5-sonnet` (Recommended)
- `anthropic/claude-3-opus`
- `openai/gpt-4-turbo`
- `google/gemini-pro`
- And more...

### Report Generation

The **Summarize** page uses LLM to generate:

- Markdown reports with all metrics
- Theoretical analysis
- Recommendations
- Experimental conclusions

## üìñ Theoretical Background

### Shannon's Information Theory

**Entropy** - Measures information content:
```
H(X) = -Œ£ p(x) log‚ÇÇ(p(x))
```

**Channel Capacity** - Maximum reliable transmission rate:
```
C = B log‚ÇÇ(1 + SNR)
```

**Rate-Distortion** - Trade-off between rate and quality:
```
R(D) = min I(X;Y) subject to E[d(X,Y)] ‚â§ D
```

### Why This Matters

Shannon proved:
1. **You cannot compress below entropy** (losslessly)
2. **Reliable communication is possible** below channel capacity
3. **There's always a rate-distortion trade-off** for lossy compression

This project makes these abstract concepts tangible!

## üîÆ Future Enhancements

### Phase 2: Audio Support

- Implement audio compressors (MP3-style, Opus-style)
- Waveform visualization
- Perceptual audio metrics

### Phase 3: Text Support

- LZ77, LZ78 algorithms
- Huffman for text
- Dictionary-based methods
- Language model-based compression

### Phase 4: Advanced Features

- Real-time streaming simulation
- Error injection and correction
- Multi-user collaboration
- Comparative studies database

## üß™ Running Tests

```bash
# Run all tests
pytest

# With coverage
pytest --cov=infocodec

# Specific test file
pytest tests/test_compressors.py
```

## üìä Example Results

### Gradient Image (64x64)

| Method | Entropy | Compression | PSNR | Time |
|--------|---------|-------------|------|------|
| Naive | 6.72 | 1.00x | ‚àû | 0.001s |
| RLE | 6.72 | 0.50x | ‚àû | 0.002s |
| Differential | 0.28 | 8.93x | ‚àû | 0.003s |
| Huffman | 6.72 | 1.19x | ‚àû | 0.015s |

### Block Pattern (64x64)

| Method | Entropy | Compression | PSNR | Time |
|--------|---------|-------------|------|------|
| Naive | 5.72 | 1.00x | ‚àû | 0.001s |
| RLE | 5.72 | 4.00x | ‚àû | 0.002s |
| Differential | 1.29 | 2.19x | ‚àû | 0.003s |
| Huffman | 5.72 | 1.40x | ‚àû | 0.014s |

## ü§ù Contributing

Contributions welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

Areas for contribution:
- New compression algorithms
- Audio/text support
- UI improvements
- Documentation
- Test coverage
- Performance optimization

## üìÑ License

MIT License - see [LICENSE](LICENSE) file.

## üôè Acknowledgments

- **Claude Shannon**: For founding information theory
- **Tutorial inspirations**: Cover & Thomas, MacKay
- **Community**: All contributors and users

## üìû Contact

- **Issues**: [GitHub Issues](https://github.com/yourusername/shannon-portrait/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/shannon-portrait/discussions)

## üêò Broader Context: Elegant Elephant

This project is one instrument in a larger research programme called **Elegant Elephant**, which proposes that compression, dimensionality reduction, quantum measurement, symmetry breaking, and philosophical notions of illusion are all the *same underlying process* ‚Äî projection from a higher-dimensional reality to a lower-dimensional observable one.

Within that framework, `shannon-portrait` studies the **information theory axis**:

| Elegant Elephant concept | This project's concrete form |
|---|---|
| Projection operator `œÄ: H ‚Üí L` | Each compression algorithm (DCT, Huffman, RLE, ‚Ä¶) |
| Information loss `I(H) > I(œÄ(H))` | Entropy, PSNR, SSIM, compression ratio metrics |
| Irreversibility of projection | Lossy vs lossless reconstruction experiments |
| Different projections reveal different aspects | Benchmark comparison across all methods |

The manifold learning axis (PHATE, t-SNE, PCA as projection operators) is studied in a sibling instrument: **Semanscope**.

See [`README-Elegant-Elephant.md`](../zinets/README-Elegant-Elephant.md) for the full unified framework.

---

*"The fundamental problem of communication is that of reproducing at one point exactly or approximately a message selected at another."* ‚Äî Claude Shannon, 1948

Built with ‚ù§Ô∏è for exploring information theory.
