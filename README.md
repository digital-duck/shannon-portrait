# Shannon Portrait - InfoCodec

**Information Coding & Encoding**: A research and educational tool for exploring Claude Shannon's Information Theory through practical image compression experiments.

## ğŸ¯ Project Overview

This project demonstrates Shannon's fundamental concepts through the thought experiment of transmitting 2D images over a 1D wire:

- **2D â†’ 1D**: Various encoding/compression methods
- **Transmission**: Simulated 1D channel
- **1D â†’ 2D**: Reconstruction with quality analysis
- **Analysis**: Information theory metrics and AI-generated reports

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/shannon-portrait.git
cd shannon-portrait

# Install the package
pip install -e .

# Or install from PyPI (when published)
pip install shannon-portrait
```

### CLI Usage

```bash
# Encode an image
infocodec encode --input shannon.png --method huffman

# Decode compressed data
infocodec decode --input compressed.dat --output restored.png

# Benchmark all methods
infocodec benchmark --input shannon.png --methods all

# Launch interactive UI
infocodec ui
```

### Streamlit UI

```bash
# Launch web interface
streamlit run infocodec/ui/app.py

# Or via CLI
infocodec ui
```

## ğŸ“š Features

### Compression Methods

| Method | Type | Best For | Compression | Quality |
|--------|------|----------|-------------|---------|
| Naive | Baseline | Comparison | 1.0x | Perfect |
| RLE | Lossless | Block patterns | 4-10x | Perfect |
| Differential | Lossless | Smooth gradients | 2-5x | Perfect |
| Huffman | Lossless | General purpose | 1.5-3x | Perfect |
| Sparse | Lossy | Quick preview | 10-50x | Variable |
| DCT | Lossy | Photos (JPEG-style) | 5-20x | Variable |

### Information Theory Metrics

- **Shannon Entropy**: H(X) = -Î£ p(x) logâ‚‚(p(x))
- **PSNR**: Peak Signal-to-Noise Ratio
- **SSIM**: Structural Similarity Index
- **Compression Ratio**: Original size / Compressed size
- **Bits per Pixel**: Total bits / Number of pixels

### Multi-Page UI

1. **âš™ï¸ Settings**: Configure algorithms, LLM integration, caching
2. **ğŸ“¤ Encode**: Upload and compress images
3. **ğŸ“¥ Decode**: Reconstruct from compressed data
4. **ğŸ“Š Diff**: Visual and quantitative quality analysis
5. **ğŸ“ Summarize**: AI-generated experimental reports

## ğŸ—ï¸ Project Structure

```
shannon-portrait/
â”œâ”€â”€ infocodec/                  # Main package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                  # Click CLI
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ base.py             # Abstract base classes
â”‚   â”‚   â”œâ”€â”€ metrics.py          # Information theory metrics
â”‚   â”‚   â”œâ”€â”€ compressors/        # Compression algorithms
â”‚   â”‚   â”‚   â””â”€â”€ image/
â”‚   â”‚   â”‚       â”œâ”€â”€ naive.py
â”‚   â”‚   â”‚       â”œâ”€â”€ rle.py
â”‚   â”‚   â”‚       â”œâ”€â”€ differential.py
â”‚   â”‚   â”‚       â”œâ”€â”€ huffman.py
â”‚   â”‚   â”‚       â”œâ”€â”€ sparse.py
â”‚   â”‚   â”‚       â””â”€â”€ dct.py
â”‚   â”‚   â””â”€â”€ reconstructors/     # Reconstruction algorithms
â”‚   â”‚       â””â”€â”€ image/
â”‚   â”‚           â”œâ”€â”€ direct.py
â”‚   â”‚           â”œâ”€â”€ progressive.py
â”‚   â”‚           â””â”€â”€ error_recovery.py
â”‚   â”œâ”€â”€ ui/                     # Streamlit interface
â”‚   â”‚   â”œâ”€â”€ app.py              # Main app
â”‚   â”‚   â”œâ”€â”€ pages/              # Multi-page app
â”‚   â”‚   â”‚   â”œâ”€â”€ 1_âš™ï¸_Settings.py
â”‚   â”‚   â”‚   â”œâ”€â”€ 2_ğŸ“¤_Encode.py
â”‚   â”‚   â”‚   â”œâ”€â”€ 3_ğŸ“¥_Decode.py
â”‚   â”‚   â”‚   â”œâ”€â”€ 4_ğŸ“Š_Diff.py
â”‚   â”‚   â”‚   â””â”€â”€ 5_ğŸ“_Summarize.py
â”‚   â”‚   â””â”€â”€ components/         # Reusable UI components
â”‚   â””â”€â”€ utils/                  # Utilities
â”‚       â”œâ”€â”€ image_utils.py
â”‚       â”œâ”€â”€ config.py
â”‚       â””â”€â”€ openrouter.py       # LLM integration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ images/
â”‚       â””â”€â”€ shannon_portrait.png
â”œâ”€â”€ tests/                      # Unit tests
â”œâ”€â”€ docs/                       # Documentation
â”œâ”€â”€ notebooks/                  # Jupyter tutorials
â”œâ”€â”€ setup.py                    # Package setup
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

## ğŸ”¬ Research Use Cases

### 1. Information Representation Study

Explore how different encodings represent the same information:

```python
from infocodec.core.compressors import COMPRESSORS
from infocodec.utils.image_utils import load_image

image = load_image("shannon.png")

for method_name, compressor_class in COMPRESSORS.items():
    compressor = compressor_class()
    compressed, metadata = compressor.compress(image)
    stats = compressor.get_stats()
    print(f"{method_name}: {stats['entropy']:.2f} bits/pixel")
```

### 2. Compression Algorithm Comparison

Benchmark multiple methods:

```bash
infocodec benchmark --input test_images/ --methods all --output results/
```

### 3. Rate-Distortion Analysis

Study the trade-off between compression and quality:

```python
qualities = [1.0, 0.9, 0.8, 0.7, 0.5, 0.3, 0.1]
for q in qualities:
    # Compress at different quality levels
    # Measure PSNR vs. compression ratio
```

### 4. Educational Demonstrations

Use the Streamlit UI for interactive teaching:

1. Show students entropy of different patterns
2. Demonstrate compression effectiveness
3. Visualize reconstruction quality
4. Compare theoretical vs. practical results

## ğŸ¤– LLM Integration (OpenRouter)

### Setup

1. Get API key from [OpenRouter.ai](https://openrouter.ai/keys)
2. Configure in Settings page or environment variable:

```bash
export OPENROUTER_API_KEY="your-key-here"
```

### Supported Models

- `anthropic/claude-3.5-sonnet` (Recommended)
- `anthropic/claude-3-opus`
- `openai/gpt-4-turbo`
- `google/gemini-pro`
- And more...

### Report Generation

The **Summarize** page uses LLM to generate:

- Markdown reports with all metrics
- Theoretical analysis
- Recommendations
- Experimental conclusions

## ğŸ“– Theoretical Background

### Shannon's Information Theory

**Entropy** - Measures information content:
```
H(X) = -Î£ p(x) logâ‚‚(p(x))
```

**Channel Capacity** - Maximum reliable transmission rate:
```
C = B logâ‚‚(1 + SNR)
```

**Rate-Distortion** - Trade-off between rate and quality:
```
R(D) = min I(X;Y) subject to E[d(X,Y)] â‰¤ D
```

### Why This Matters

Shannon proved:
1. **You cannot compress below entropy** (losslessly)
2. **Reliable communication is possible** below channel capacity
3. **There's always a rate-distortion trade-off** for lossy compression

This project makes these abstract concepts tangible!

## ğŸ”® Future Enhancements

### Phase 2: Audio Support

- Implement audio compressors (MP3-style, Opus-style)
- Waveform visualization
- Perceptual audio metrics

### Phase 3: Text Support

- LZ77, LZ78 algorithms
- Huffman for text
- Dictionary-based methods
- Language model-based compression

### Phase 4: Advanced Features

- Real-time streaming simulation
- Error injection and correction
- Multi-user collaboration
- Comparative studies database

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest

# With coverage
pytest --cov=infocodec

# Specific test file
pytest tests/test_compressors.py
```

## ğŸ“Š Example Results

### Gradient Image (64x64)

| Method | Entropy | Compression | PSNR | Time |
|--------|---------|-------------|------|------|
| Naive | 6.72 | 1.00x | âˆ | 0.001s |
| RLE | 6.72 | 0.50x | âˆ | 0.002s |
| Differential | 0.28 | 8.93x | âˆ | 0.003s |
| Huffman | 6.72 | 1.19x | âˆ | 0.015s |

### Block Pattern (64x64)

| Method | Entropy | Compression | PSNR | Time |
|--------|---------|-------------|------|------|
| Naive | 5.72 | 1.00x | âˆ | 0.001s |
| RLE | 5.72 | 4.00x | âˆ | 0.002s |
| Differential | 1.29 | 2.19x | âˆ | 0.003s |
| Huffman | 5.72 | 1.40x | âˆ | 0.014s |

## ğŸ¤ Contributing

Contributions welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

Areas for contribution:
- New compression algorithms
- Audio/text support
- UI improvements
- Documentation
- Test coverage
- Performance optimization

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

- **Claude Shannon**: For founding information theory
- **Tutorial inspirations**: Cover & Thomas, MacKay
- **Community**: All contributors and users

## ğŸ“ Contact

- **Issues**: [GitHub Issues](https://github.com/yourusername/shannon-portrait/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/shannon-portrait/discussions)

---

*"The fundamental problem of communication is that of reproducing at one point exactly or approximately a message selected at another."* â€” Claude Shannon, 1948

Built with â¤ï¸ for exploring information theory.
